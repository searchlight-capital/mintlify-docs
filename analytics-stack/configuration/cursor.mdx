---
title: 'Cursor Configuration'
description: 'Setting up Cursor for Data Engineering'
---

Cursor is our primary IDE for building data pipelines. It integrates with Snowflake and our custom Prime MCP server to provide context-aware coding assistance.

## 1. Install Cursor
Download and install [Cursor](https://cursor.sh/) if you haven't already.

## 2. Connect to GitHub
1.  Open Cursor.
2.  Clone the `fiber_map_dbt` repository (or your relevant project).
3.  Ensure you are signed in to GitHub within Cursor to access Copilot features.

## 3. Configure Snowflake MCP
To enable Cursor to query Snowflake directly:

1.  Go to **Cursor Settings** > **Features** > **MCP**.
2.  Add a new **STDIO** MCP server.
3.  **Command**: Use the command to run the Snowflake JDBC/MCP connector (consult the Engineering team for the specific Docker or local Java command).
4.  **Environment Variables**:
    *   `SNOWFLAKE_ACCOUNT`: Your account identifier (e.g., `zh06779.north-europe.azure`).
    *   `SNOWFLAKE_USER`: Your username.
    *   `SNOWFLAKE_ROLE`: `SYSADMIN` (or your developer role).
    *   `SNOWFLAKE_WAREHOUSE`: `COMPUTE_WH`.
    *   `SNOWFLAKE_AUTHENTICATOR`: `externalbrowser` (recommended for SSO).

## 4. Configure Prime MCP
To enable dbt context (schema awareness):

1.  Go to **Cursor Settings** > **Features** > **MCP**.
2.  Add a new **SSE** (Server-Sent Events) MCP server.
3.  **URL**: Point to the internal Prime server URL (e.g., `https://prime-mcp.internal`).

## 5. Install Extensions
Recommended extensions for this stack:
*   **dbt Power User**: For dbt project navigation and execution.
*   **YAML**: For editing dbt configuration files.
*   **SQLTools**: For database connection management (optional, if not using MCP exclusively).

