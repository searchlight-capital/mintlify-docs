---
title: 'Analytics Stack Overview'
description: 'Modern data infrastructure powering Searchlight analytics'
---

## Objectives

Our analytics stack is designed to achieve two primary goals:

1. **Rapid Development**: Enable data engineers to build and deploy new analysis pipelines with speed and confidence.
2. **Self-Service**: Empower business users to answer their own questions with high confidence, without always relying on an analyst.

## The Stack

We leverage a modern stack integrating Gen-AI features directly into our workflows.

### Core Infrastructure
*   **Snowflake**: Central cloud data platform for storage and compute.
*   **dbt (Data Build Tool)**: Transformation framework for building reliable data pipelines.
*   **Lightdash**: BI platform for self-serve dashboarding, integrated tightly with dbt.
*   **GitHub**: Version control and collaboration.

### AI & Development Tools
*   **Cursor**: AI-powered code editor used to build pipelines, charts, and dashboards.
*   **Claude.ai**: Advanced AI assistant for natural language queries and analysis.
*   **Snowflake MCP Server**: Connects Claude and Cursor directly to Snowflake data for context-aware assistance.
*   **Prime**: Custom MCP server that serves dbt project context (manifest files) to Claude, ensuring AI understands our specific data model.
*   **Braintrust**: Evaluation framework to test and ensure the quality of AI outputs.
*   **Mintlify**: Documentation platform (this site).

## Key Repositories

<CardGroup cols={2}>
  <Card
    title="Searchlight GitHub Org"
    icon="github"
    href="https://github.com/searchlight-capital"
  >
    Central organization for all codebases.
  </Card>
  <Card
    title="Cursor Rules"
    icon="file-code"
    href="https://github.com/searchlight-capital/cursor-rules"
  >
    Shared gold standard rules for AI code generation.
  </Card>
  <Card
    title="Prime"
    icon="server"
    href="https://github.com/searchlight-capital/prime"
  >
    Custom MCP server for dbt context.
  </Card>
  <Card
    title="Analytics Evals"
    icon="check-double"
    href="https://github.com/searchlight-capital/analytics-evals"
  >
    Braintrust evaluation scripts and tests.
  </Card>
  <Card
    title="Mintlify Docs"
    icon="book"
    href="https://github.com/searchlight-capital/mintlify-docs"
  >
    Source code for this documentation site.
  </Card>
  <Card
    title="Example dbt Project"
    icon="database"
    href="https://github.com/searchlight-capital/fiber_map_dbt"
  >
    Reference implementation (Fiber Map).
  </Card>
</CardGroup>

## Why We Chose These Tools

*   **dbt**: Because it is code-based and widely adopted, AI tools are exceptionally proficient at writing and maintaining dbt scripts.
*   **Lightdash**: Built on a "dashboards as code" philosophy, allowing AI to easily read and write dashboard configurations. Its semantic layer integrates tightly with dbt, enabling re-use of semantic definitions across the stack.
*   **Snowflake-managed MCP Server**: Provides direct data access with zero infrastructure management compared to third-party alternatives.
*   **Prime**: We found that AI assistants are powerful SQL writers but struggle with semantic layer queries. Prime bridges this gap by extracting context from the dbt and Lightdash data models and exposing it to AI in a streamlined form, ensuring generated SQL is grounded in correct definitions.
*   **Braintrust**: The leading platform for LLM evaluations, ensuring our AI features remain reliable.
*   **Mintlify**: Provides beautiful, easy-to-use documentation that can be auto-generated by AI directly from our dbt and Lightdash codebases.

## How It Fits Together

1.  **Data Ingestion**: Raw data lands in Snowflake.
2.  **Transformation**: Developers use **Cursor** + **Prime** to build **dbt** models.
3.  **Presentation**:
    *   **Lightdash** consumes dbt models for trusted dashboards.
    *   **Claude.ai** (via **Snowflake MCP**) queries data directly for ad-hoc analysis.
4.  **Documentation**: **Mintlify** keeps knowledge accessible.
